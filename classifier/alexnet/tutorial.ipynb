{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WiDS Tel Aviv\n",
    "## Tutorial â€“ Dealing with the Lack of Audio Data\n",
    "In recent years, speech data is receiving spotlight for various applications in deep learning, from Automatic Speech Recognition (ASR) system to source separation. And yet, there are not many augmentation techniques explored for speech data compared to those of image data. Thus, in this track, we will explore various methods to augment speech data. This hands-on tutorial will work along the task of building a simple speech classifier with the Speech Commands Zero to Nine (SC09) dataset available by TensorFlow and go over traditional augmentation techniques, transfer learning, GAN augmentation, and style transfer to increase the classification accuracy. Participants are required to download the libraries and pre-trained models, which will be available in late-January."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample audio from sc09 dataset\n",
    "import os\n",
    "from glob import glob\n",
    "import IPython.display as ipd\n",
    "\n",
    "label_paths = glob('../../data/sc09/*')\n",
    "\n",
    "for label_path in label_paths:\n",
    "    sample_wav = glob(os.path.join(label_path, '*.wav'))[0]\n",
    "    print(\"Class:\", os.path.split(os.path.dirname(sample_wav))[1])\n",
    "    ipd.display(ipd.Audio(sample_wav))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wav2img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sample wav files into spectrogram images\n",
    "# load sample audio from sc09 dataset\n",
    "%matplotlib inline\n",
    "import os\n",
    "from glob import glob\n",
    "import IPython.display as ipd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "\n",
    "label_paths = glob('../../data/sc09/*/*.wav')\n",
    "LEN = 16000\n",
    "\n",
    "for sample_wav in label_paths:\n",
    "    ipd.display(ipd.Audio(sample_wav))\n",
    "    \n",
    "    # read .wav\n",
    "    rate, data = wavfile.read(sample_wav)\n",
    "    \n",
    "    if len(data) > LEN:\n",
    "        data = data[:LEN]\n",
    "    else:\n",
    "        data = np.pad(data, (0, max(0, LEN - len(data))), \"constant\")\n",
    "    \n",
    "    # spectrogram img\n",
    "    fig,ax = plt.subplots(1)\n",
    "    fig.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "    ax.axis('off')\n",
    "    pxx, freqs, bins, im = ax.specgram(x=data, Fs=rate, noverlap=384, NFFT=512)\n",
    "    ax.axis('off')\n",
    "    fig.savefig(sample_wav[:-4] + '.jpg', dpi=300, frameon='false')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Tensorboard for training and evaluation\n",
    "# Describe the code in presentation\n",
    "# Let people inference with sample data\n",
    "\n",
    "# Some basic imports and and setups\n",
    "import cv2, random\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Parameters\n",
    "ckpt_path = '../training/gender_gan/checkpoint/model_epoch10.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of test images\n",
    "image_dir = glob('../../data/sc09/*/*_0.jpg')\n",
    "image_dir = random.sample(image_dir, 3)\n",
    "\n",
    "# Load test images\n",
    "imgs = []\n",
    "gt = []\n",
    "for f in image_dir:\n",
    "    imgs.append(cv2.imread(f))\n",
    "    gt.append(os.path.split(os.path.dirname(f))[1])\n",
    "    \n",
    "# Plot images\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "for i, img in enumerate(imgs):\n",
    "    fig.add_subplot(1,3,i+1)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(gt[i])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will create placeholder for the dropout rate and the inputs and create an AlexNet object. Then we will link the activations from the last layer to the variable score and define an op to calculate the softmax values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from model import AlexNetModel\n",
    "\n",
    "# Placeholders\n",
    "x = tf.placeholder(tf.float32, [1, 227, 227, 3])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "labels = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "\n",
    "# Model\n",
    "model = AlexNetModel(num_classes=10, dropout_keep_prob=keep_prob)\n",
    "score = model.inference(x)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Load pre-trained weights\n",
    "    saver.restore(sess, ckpt_path)\n",
    "\n",
    "    # Create figure handle\n",
    "    fig2 = plt.figure(figsize=(15,6))\n",
    "    \n",
    "    # Loop over all images\n",
    "    for i, image in enumerate(imgs):\n",
    "        \n",
    "        # Convert image to float32 and resize it\n",
    "        img = cv2.resize(image.astype(np.float32), (227,227))\n",
    "        img = img.reshape((1,227,227,3))\n",
    "        \n",
    "        # Run the session and calculate the class probability\n",
    "        probs = sess.run(score, feed_dict={x: img, keep_prob: 1})\n",
    "        \n",
    "        # Get the class name of the class with the highest probability\n",
    "        class_name = labels[np.argmax(probs)]\n",
    "        \n",
    "        # Load audio\n",
    "        print(\"Class: \" + gt[i])\n",
    "        ipd.display(ipd.Audio(image_dir[i][:-4] + '.wav'))\n",
    "        \n",
    "        # Plot image with class name and prob in the title\n",
    "        fig2.add_subplot(1,3,i+1)\n",
    "        plt.title(\"Pred: \" + class_name + \", Prob: %.4f\" %probs[0,np.argmax(probs)])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add noise to train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "from scipy.io import wavfile\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "LEN = 16000\n",
    "NOISE_FREQUENCY = 0.8\n",
    "\n",
    "noise_path = glob('../../data/_background_noise_/*.wav')\n",
    "noises = []\n",
    "\n",
    "for noise_file in noise_path:\n",
    "    print(os.path.basename(noise_file)[:-4])\n",
    "    noise = wavfile.read(noise_file)[1][:LEN]\n",
    "    noises.append(noise)\n",
    "    ipd.display(ipd.Audio(noise_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load train audio\n",
    "path = '../../data/sc09/*/*.wav'\n",
    "wav_path = glob(path)\n",
    "random.shuffle(wav_path)\n",
    "\n",
    "# add background noise\n",
    "for idx, wave in enumerate(wav_path):\n",
    "    data = wavfile.read(wave)[1]\n",
    "    if idx <= len(wav_path) * NOISE_FREQUENCY:\n",
    "        if len(data) < LEN:\n",
    "            data = np.pad(data, (0, max(0, LEN - len(data))), \"constant\")\n",
    "        else:\n",
    "            data = data[:LEN]\n",
    "        index = random.randint(0, 4)\n",
    "        noise_data = noises[index]\n",
    "        wavfile.write(wave[:-4] + '_noise.wav', LEN, data + noise_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint and turn it into a numpy file\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "from model import AlexNetModel\n",
    "\n",
    "\n",
    "# Edit just these\n",
    "FILE_PATH = '../training/speech_command/checkpoint/model_epoch10.ckpt'\n",
    "NUM_CLASSES = 20\n",
    "OUTPUT_FILE = 'sc_epoch10.npy'\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x = tf.placeholder(tf.float32, [128, 227, 227, 3])\n",
    "    model = AlexNetModel(num_classes=NUM_CLASSES)\n",
    "    model.inference(x)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    layers = ['conv1', 'conv2', 'conv3', 'conv4', 'conv5', 'fc8']\n",
    "    data = {\n",
    "        'conv1': [],\n",
    "        'conv2': [],\n",
    "        'conv3': [],\n",
    "        'conv4': [],\n",
    "        'conv5': [],\n",
    "        'fc8': []\n",
    "    }\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, FILE_PATH)\n",
    "\n",
    "        for op_name in layers:\n",
    "          with tf.variable_scope(op_name, reuse = True):\n",
    "            biases_variable = tf.get_variable('biases')\n",
    "            weights_variable = tf.get_variable('weights')\n",
    "            data[op_name].append(sess.run(biases_variable))\n",
    "            data[op_name].append(sess.run(weights_variable))\n",
    "\n",
    "        np.save(OUTPUT_FILE, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Synthesis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
