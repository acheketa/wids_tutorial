# wids_tutorial

- This repo was created for WiDS tutorial participants.
- Please refer to [WiDS TLV](https://widstlv.com/chae-young-lee/) and [slides](https://docs.google.com/presentation/d/1MFTZMGP1Ub9AXWTaTwqiDTwtLC8fpOARwo7kNOCpXDk/edit?usp=sharing).

## Tutorial â€“ Dealing with the Lack of Audio Data

In recent years, speech data is receiving spotlight for various applications in deep learning, from Automatic Speech Recognition (ASR) system to source separation. And yet, there are not many augmentation techniques explored for speech data compared to those of image data. Thus, in this track, we will explore various methods to augment speech data. This hands-on tutorial will work along the task of building a simple speech classifier with the Speech Commands Zero to Nine (SC09) dataset available by TensorFlow and go over traditional augmentation techniques, transfer learning, GAN augmentation, and style transfer to increase the classification accuracy. Participants are required to download the libraries and pre-trained models, which will be available in late-January.

## Reference

- [Speech Commands dataset (TensorFlow)](https://www.tensorflow.org/tutorials/sequences/audio_recognition)
- [CycleGAN TensorFlow](https://github.com/xhujoy/CycleGAN-tensorflow)
- [AlexNet Finetuning TensorFlow](https://github.com/dgurkaynak/tensorflow-cnn-finetune/tree/master/alexnet)
